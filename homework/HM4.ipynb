{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HM4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwdYDCtJVTHh",
        "outputId": "1020111b-7129-4a95-ad5c-13ba9be6ccae"
      },
      "source": [
        "#import the data\n",
        "from keras.datasets import cifar10\n",
        "import numpy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czdUXEYaWDFH",
        "outputId": "66a937c3-e331-4f9a-b0f2-129940086d60"
      },
      "source": [
        "#Define one-hot encoding function\n",
        "\n",
        "def to_one_hot(y, num_class=10):\n",
        "    one_hot_encode = []\n",
        "    for c in y:\n",
        "        arr = numpy.zeros(num_class)\n",
        "        arr [c] = 1\n",
        "        one_hot_encode.append(arr)\n",
        "    one_hot_encode = numpy.reshape(one_hot_encode,(len(y), num_class))\n",
        "    return one_hot_encode\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhT8i-F3WP94",
        "outputId": "01223b1c-0753-40f9-982c-731b3c810ad4"
      },
      "source": [
        "#Randomly partition the training set into training and validation sets\n",
        "rand_indices = numpy.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNV3okQCWe4T",
        "outputId": "285b153a-e379-444e-b202-d0a86689e1c5"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation ('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation ('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation ('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_88 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_117 (Bat (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_88 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_88 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_89 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_118 (Bat (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_89 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_89 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_90 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_119 (Bat (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_90 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_90 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_29 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_120 (Bat (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 365,898\n",
            "Trainable params: 361,354\n",
            "Non-trainable params: 4,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6vX_6_KWjJZ"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 1E-3 # to be tuned!\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=learning_rate, momentum=0.9),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSrG130bWnLz",
        "outputId": "390fd24e-61de-4d38-f45b-37cfb898a6fb"
      },
      "source": [
        "history = model.fit(x_tr, y_tr, batch_size=32, epochs=30, validation_data=(x_val, y_val))"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.8709 - acc: 0.3654 - val_loss: 1.2774 - val_acc: 0.5489\n",
            "Epoch 2/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2396 - acc: 0.5545 - val_loss: 1.1369 - val_acc: 0.6035\n",
            "Epoch 3/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0640 - acc: 0.6210 - val_loss: 0.9648 - val_acc: 0.6636\n",
            "Epoch 4/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9620 - acc: 0.6579 - val_loss: 1.1476 - val_acc: 0.5984\n",
            "Epoch 5/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9039 - acc: 0.6787 - val_loss: 0.9304 - val_acc: 0.6725\n",
            "Epoch 6/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8524 - acc: 0.6954 - val_loss: 0.8705 - val_acc: 0.6915\n",
            "Epoch 7/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7966 - acc: 0.7161 - val_loss: 1.0652 - val_acc: 0.6407\n",
            "Epoch 8/30\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.7492 - acc: 0.7338 - val_loss: 0.9164 - val_acc: 0.6838\n",
            "Epoch 9/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7247 - acc: 0.7406 - val_loss: 1.3957 - val_acc: 0.5650\n",
            "Epoch 10/30\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.6937 - acc: 0.7565 - val_loss: 0.8233 - val_acc: 0.7130\n",
            "Epoch 11/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6699 - acc: 0.7602 - val_loss: 0.7965 - val_acc: 0.7303\n",
            "Epoch 12/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6464 - acc: 0.7667 - val_loss: 0.9243 - val_acc: 0.7059\n",
            "Epoch 13/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6206 - acc: 0.7792 - val_loss: 0.8566 - val_acc: 0.7133\n",
            "Epoch 14/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5866 - acc: 0.7919 - val_loss: 0.8075 - val_acc: 0.7304\n",
            "Epoch 15/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5701 - acc: 0.7980 - val_loss: 0.8592 - val_acc: 0.7127\n",
            "Epoch 16/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5545 - acc: 0.8039 - val_loss: 0.8638 - val_acc: 0.7142\n",
            "Epoch 17/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5294 - acc: 0.8109 - val_loss: 0.9314 - val_acc: 0.6974\n",
            "Epoch 18/30\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.5157 - acc: 0.8139 - val_loss: 0.7586 - val_acc: 0.7458\n",
            "Epoch 19/30\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.5019 - acc: 0.8223 - val_loss: 0.7089 - val_acc: 0.7614\n",
            "Epoch 20/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4910 - acc: 0.8245 - val_loss: 0.7414 - val_acc: 0.7535\n",
            "Epoch 21/30\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.4716 - acc: 0.8300 - val_loss: 0.6713 - val_acc: 0.7771\n",
            "Epoch 22/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4520 - acc: 0.8386 - val_loss: 0.6625 - val_acc: 0.7802\n",
            "Epoch 23/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4410 - acc: 0.8402 - val_loss: 0.6982 - val_acc: 0.7750\n",
            "Epoch 24/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4260 - acc: 0.8494 - val_loss: 0.6910 - val_acc: 0.7731\n",
            "Epoch 25/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4151 - acc: 0.8522 - val_loss: 0.6657 - val_acc: 0.7850\n",
            "Epoch 26/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4023 - acc: 0.8572 - val_loss: 0.7170 - val_acc: 0.7700\n",
            "Epoch 27/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3877 - acc: 0.8600 - val_loss: 0.7705 - val_acc: 0.7521\n",
            "Epoch 28/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3846 - acc: 0.8624 - val_loss: 0.7458 - val_acc: 0.7633\n",
            "Epoch 29/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3706 - acc: 0.8684 - val_loss: 0.7791 - val_acc: 0.7583\n",
            "Epoch 30/30\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3561 - acc: 0.8726 - val_loss: 0.6574 - val_acc: 0.7907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "7nWfjhx4WptH",
        "outputId": "1a4a5d7f-bd4c-409c-aa27-305bd8377ed8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WeU-KLj82ys",
        "outputId": "151760f2-8397-4f70-ec59-37a25d9bcd74"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation ('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation ('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation ('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_91 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_121 (Bat (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_91 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_91 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_122 (Bat (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_92 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_92 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_93 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_123 (Bat (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_93 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_93 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_30 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_124 (Bat (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 365,898\n",
            "Trainable params: 361,354\n",
            "Non-trainable params: 4,544\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsgkQYeV8_vs"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 1E-3 # to be tuned!\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=learning_rate, momentum=0.9),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbFQtglJ9EvZ",
        "outputId": "ffed8e0f-d13a-417e-8c8c-ee34b9bab857"
      },
      "source": [
        "history1 = model.fit(x_train, y_train_vec, batch_size=32, epochs=30)"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1688 - acc: 0.5840\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.0037 - acc: 0.6435\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.9134 - acc: 0.6769\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8518 - acc: 0.7001\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8008 - acc: 0.7179\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7542 - acc: 0.7350\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7234 - acc: 0.7441\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6886 - acc: 0.7572\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6623 - acc: 0.7667\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6332 - acc: 0.7762\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6086 - acc: 0.7880\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5903 - acc: 0.7913\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5714 - acc: 0.8002\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5512 - acc: 0.8061\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5316 - acc: 0.8129\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5125 - acc: 0.8182\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4951 - acc: 0.8239\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4865 - acc: 0.8270\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4674 - acc: 0.8345\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4564 - acc: 0.8371\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4427 - acc: 0.8418\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4258 - acc: 0.8477\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4184 - acc: 0.8516\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4016 - acc: 0.8561\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3935 - acc: 0.8600\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3789 - acc: 0.8651\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3678 - acc: 0.8700\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3641 - acc: 0.8716\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3425 - acc: 0.8765\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3448 - acc: 0.8750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrv-XkPf9iKg",
        "outputId": "419de4ed-f1e9-48c6-8fee-6084136f7818"
      },
      "source": [
        "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7511 - acc: 0.7640\n",
            "loss = 0.751061201095581\n",
            "accuracy = 0.7639999985694885\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
